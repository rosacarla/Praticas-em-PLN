# -*- coding: utf-8 -*-
"""S3-Similaridade Léxica [GABARITO].ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lyLN_LVD0HxDc6pHCj_VAyVI_43SIHgh

# GABARITO
# Similaridade Léxica
## Processamento de Linguagem Natural
Nesta atividade você realizará atividades práticas relacionadas a  **Similaridade léxica**, visando entender qual o seu papel nas mais diversas aplicações de PLN.

##**Medidas de similaridade**
Existe uma série de diferentes cálculos/medidas que indicam a similaridade léxica entre palavras, as chamamos de *string-based*.

![String-based similarity measures](https://docs.google.com/uc?export=download&id=1iO4zT9lTIO4-XsAB-P9_BddOIJwjwMRJ)

A seguir uma série de exemplos de algumas das medidas de similaridade léxica da figura acima.

### **Levenshtein (edit) distance**

A distância de Levenshtein entre duas palavras é o número mínimo de edições de um caractere (inserções, exclusões ou substituições) necessárias para alterar uma palavra pela outra. Usaremos para comparar **PALAVRAS/TOKENS**.
"""

# Define 4 palavras diferentes
p1 = "padeiro"
p2 = "pandeiro"
p3 = "bombeiro"
p4 = "padaria"

# Não há necessidade de implementar a função de edit distance visto que o NLTK já a implementa
import nltk

nltk.edit_distance(p1, p2)

nltk.edit_distance(p1, p3)

nltk.edit_distance(p1, p4)

nltk.edit_distance(p3, p4)

"""#### Atividade prática - Construindo um **verificador ortográfico simples**"""

# Lista contendo o dicionário de palavras válidas
dicionario = ['beneficente','cumprimento', 'comprimento', 'tráfego', 'tráfico', 'iminente', 'eminente', 'descrição', 'discrição']

# Função que verifica se palavra está no dicionário
def verificar(p):
  # Se palavra não está no dicionário
  if p not in dicionario:

    print("Palavra incorreta!")

#A seguir pediremos que o usuário digite uma palavra
palavra = input("Digite uma palavra: ")

# Verifica palavra informada pelo usuário
verificar(palavra)

"""Re-implemente a função `verificar(p)` de modo que:
1.  Caso a palavra digitada não exista no dicionário, ela sugira todas as outras que tenham uma distância de edição de valor 1 da palavra digitada.
> **DICA**: Para percorrer a lista de palavras você pode utilizar o comando `for palavra in dicionario:`
2.  Ao invés de receber apenas uma palavra, a função receba uma sentença inteira, faça a tokenização da mesma, e ofereça sugestões para todas palavras que nao se encontram no dicionário (caso as mesmas tenham distância de edição igual a 1)
3. **BÔNUS**: Obter uma lista de palavras de maior abrangência, abrir arquivo e popular o dicionário (https://github.com/pythonprobr/palavras)

### **N-grams**
O N-grams são basicamente um conjunto de caracteres/palavras co-ocorrentes em uma determinada janela de abertura. Usaremos tanto para comparar **CARACTERES** quanto **PALAVRAS**.
"""

# Não há necessidade de implementar uma função de n-grams - o NLTK já implementa
import nltk
from nltk.util import ngrams
# Necessário pois utilizaremos o tokenizador
nltk.download('punkt')

"""#### N-Grams de **PALAVRAS**"""

# Função para gerar n-grams de palavras a partir de uma sentença.
def extrair_ngrams_palavras(sent, n):
    n_grams = ngrams(nltk.word_tokenize(sent, language='portuguese'), n)
    return [ ' '.join(grams) for grams in n_grams]

texto = 'Esta é uma sentença para testarmos n-grams de palavras.'

print("1-gram: ", extrair_ngrams_palavras(texto, 1))
print("2-gram: ", extrair_ngrams_palavras(texto, 2))
print("3-gram: ", extrair_ngrams_palavras(texto, 3))
print("4-gram: ", extrair_ngrams_palavras(texto, 4))

"""#### N-Grams de **CARACTERES**"""

# Função para gerar n-grams de caracteres a partir de um texto.
def extrair_ngrams_char(texto, n):
  # Cria lista com caracteres
  chars = [c for c in texto]
  n_grams = ngrams(chars,n)
  return [ ' '.join(grams) for grams in n_grams]

texto = "Sentença para testarmos n-grams de caracteres"

print("1-gram: ", extrair_ngrams_char(texto,1))
print("2-gram: ", extrair_ngrams_char(texto,2))
print("3-gram: ", extrair_ngrams_char(texto,3))
print("4-gram: ", extrair_ngrams_char(texto,4))

"""> #### **IMPORTANTE**: Mas quais seriam algumas das aplicações dos n-grams?

#### 1) Reconhecimento de entidades / Chunking
Imagine que você tenha um corpus (conjunto de documentos) e visualize os seguintes n-grams:

1.   São Paulo (2-gram)
2.   processamento de linguagem natural (4-gram)
3.   o presidente alega que é inocente (6-gram)

Ao fazermos um levantamento de frequência, possivelmente os exemplos 1 e 2 ocorram com mais frequência no corpus. Agora se aplicarmos um modelo de probabilidade podemos **encontrar entidades** compostas por múltiplas palavras no texto.

#### 2) Predição de palavras
Seguindo a mesma linha anterior, é possível também utilizar os n-grams para fazer **predições de palavras**. Por exemplo, se houver a sentença parcial "*Meu beatle favorito é*", a probabilidade da próxima palavra ser "*John*", "*Paul*", "*George*" ou "*Ringo*" é bem maior que o restante das palavras do vocabulário.

#### 3) Correção ortográfica
A sentença "*beba vino*" poderia ser corrigida para "*beba vinho*" se você soubesse que a palavra "*vinho*" tem uma alta probabilidade de ocorrência após a palavra "*beba*". Além disso, a sobreposição de letras entre "*vino*" e "*vinho*" é alta (i.e., baixa distância de edição).

#### 4) e por fim, nosso assunto atual, *Similaridade léxica*
Vamos extrair 2-grams de caracteres das duas palavras a seguir.
"""

p1 = "parar"
p2 = "parado"

# 4 bi-grams - 2 únicos
print("2-grams: ", extrair_ngrams_char(p1,2))
# 5 bi-grams - 5 únicos
print("2-grams: ", extrair_ngrams_char(p2,2))

"""Para **cálculo de similaridade utilizando n-grams** usamos a fórmula: `S = 2C / A + B`

Onde:
* A é o número de n-grams únicos na primeira palavra
* B é o número de n-grams únicos na segunda palavra
* C é o número de n-grams únicos compartilhados

Portanto, neste exemplo o cálculo ficaria: `S = 2 * 2 / 2 + 5 = 0.57`
"""

# Obtém os N-Grams únicos
def uniqueNgrams(ngrams):

  ngrams = [item for item in ngrams if ngrams.count(item) == 1]

  return ngrams

# Obtém os N-Grams compartilhados
def sharedNgrams(ng1, ng2):

  return list(set(ng1) & set(ng2))

# Calcula a similaridade através dos N-Grams
def nGramsSimilarity(ng1, ng2):

  # Obtém N-Grams únicos para cada palavra
  ung1 = uniqueNgrams(ng1)
  ung2 = uniqueNgrams(ng2)

  #Número de N-Grams únicos da palavra 1
  A = len(ung1)
  #Número de N-Grams únicos da palavra 2
  B = len(ung2)
  #Número de N-Grams compartilhados entre as palavras
  C = len(sharedNgrams(ung1, ung2))

  return (2 * C) / (A + B)

nGramsSimilarity(extrair_ngrams_char(p1,2), extrair_ngrams_char(p2,2))

"""### **Jaccard distance**

A distância de Jaccard é definida como o *tamanho da interseção dividida pelo tamanho da união de dois conjuntos*. Usaremos tanto para comparar **CARACTERES** quanto **PALAVRAS**.

Sentença 1: Eu gosto de fazer programas usando processamento de linguagem natural

Sentença 2: Eu sei programar técnicas de processamento de linguagem natural

![String-based similarity measures](https://docs.google.com/uc?export=download&id=11Wh0zM0nTqDIMPSjgM3S3LSgT9K1Xlcr)
"""

# Não há necessidade de implementar uma função de jaccard - o NLTK já implementa
import
# Necessário pois utilizaremos o tokenizador
nltk.download('punkt')

"""#### Jaccard em **CARACTERES**"""

w1 = set('tráfico')
w2 = set('tráfego')

nltk.jaccard_distance(w1, w2)

"""> **IMPORTANTE**: Esta medida calcula a **distância** entre os dois termos, portanto quanto maior o valor, mais distantes (diferentes) são os termos!

> **ATENÇÃO**: a função `jaccard_distance()` não aceita strings, você deve transformar sua entrada em `set`

#### Jaccard em **PALAVRAS**
"""

s1 = 'Eu gosto de fazer programas usando processamento de linguagem natural'
s2 = 'Eu sei programar técnicas de processamento de linguagem natural'

# Tokeniza e transforma lista de tokens em set
s1_set = set(nltk.word_tokenize(s1, language='portuguese'))
s2_set = set(nltk.word_tokenize(s2, language='portuguese'))

nltk.jaccard_distance(s1_set, s2_set)

"""#### **Quiz**

1. Qual etapa de pré-processamento poderíamos aplicar para obter uma pontuação ainda maior de Jaccard no exemplo acima? *Dica*: verifique as palavras que não estão fazendo intersecção, porém tem sentido similar.
2. No caso das sentenças a seguir, qual o valor de Jaccard? O valor refletiu a similaridade entre as sentenças?

**Sentença 1**: Presidente responde a imprensa no Paraná

**Sentença 2**: Bolsonaro fala em Curitiba

## Referências e Material complementar

*   [Edit Distance & Jaccard](https://python.gotrained.com/nltk-edit-distance-jaccard-distance/)
*   [N-Grams Tutorial](https://www.kaggle.com/rtatman/tutorial-getting-n-grams)
*   [Introduction to N-Grams: What Are They and Why Do We Need Them?](https://blog.xrds.acm.org/2017/10/introduction-n-grams-need/)
*   [Overview of Text Similarity metrics](https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50)

Este notebook foi produzido por Prof. [Lucas Oliveira](http://lattes.cnpq.br/3611246009892500).
"""